{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluation Demo\n",
    "Demonstrates RAG evaluation pipeline using first test case from goldens:\n",
    "1. Load golden (Q&A pair)\n",
    "2. Retrieve context (AWS Knowledge Base)\n",
    "3. Generate RAG response\n",
    "4. RAG Triad metrics (Faithfulness, Contextual Relevancy, Answer Relevancy)\n",
    "5. Evaluate using GEval\n",
    "6. Generate report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Analyze Test Case\n",
    "\n",
    "Loads first golden from synthetic_data/goldens.json to demonstrate:\n",
    "- Input query for RAG evaluation\n",
    "- Expected output (ground truth)\n",
    "- Context length and source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Test Case Analysis:\n",
      "\n",
      "Input Query:\n",
      "What aspects of Lisp contributed to its prominence over PL/I in AI programming?\n",
      "\n",
      "Expected Output:\n",
      "Lisp's prominence over PL/I in AI programming can be attributed to several key aspects that aligned well with the needs of AI development:\n",
      "\n",
      "1. **Symbolic Computation**: Lisp was uniquely suited for symbolic computation, a cornerstone of AI programming. It allowed for easy manipulation of symbols and lists, which was essential for representing knowledge and reasoning in AI systems.\n",
      "\n",
      "2. **Flexibility & Extensibility**: The language's inherent flexibility allowed programmers to define their own syntax and new language features easily, enabling rapid experimentation and adaptation to complex AI challenges.\n",
      "\n",
      "3. **Dynamic Typing and Garbage Collection**: Lisp's dynamic typing and automatic memory management via garbage collection allowed AI developers to focus more on problem-solving rather than low-level memory management, which was often cumbersome in languages like PL/I.\n",
      "\n",
      "4. **Interactive Development Environment**: Lisp provided an interactive environment that supported quick prototyping and iterative development, which was crucial for exploring and refining AI algorithms.\n",
      "\n",
      "5. **Recursive Functions**: The language's strong support for recursion made it a natural fit for AI applications requiring iterative and recursive problem-solving methods, such as natural language processing and machine learning.\n",
      "\n",
      "These attributes made Lisp a compelling choice for AI developers, leading to its widespread adoption despite the availability of other languages like PL/I.\n",
      "\n",
      "Context Documents: 3\n",
      "\n",
      "Source File: ./data/paul_graham/paul_graham_essay.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd  # for better data visualization\n",
    "\n",
    "def load_test_cases(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "test_cases = load_test_cases('./synthetic_data/goldens.json')\n",
    "\n",
    "first_case = test_cases[0]\n",
    "print(\"First Test Case Analysis:\")\n",
    "print(\"\\nInput Query:\")\n",
    "print(first_case['input'])\n",
    "print(\"\\nExpected Output:\")\n",
    "print(first_case['expected_output'])\n",
    "print(\"\\nContext Documents:\", len(first_case['context']))\n",
    "print(\"\\nSource File:\", first_case['source_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Retrieval\n",
    "Uses AWS Bedrock Agent to fetch relevant passages:\n",
    "- Configurable results via `RAGConfig.NUMBER_OF_RESULTS`\n",
    "- Retrieves context for input query\n",
    "- Returns formatted passages from Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Query: What aspects of Lisp contributed to its prominence over PL/I in AI programming?\n",
      "\n",
      "Number of contexts retrieved: 3\n",
      "\n",
      "Retrieved Contexts:\n",
      "\n",
      "Context 1:\n",
      "What these programs really showed was that there's a subset of natural language that's a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they co...\n",
      "\n",
      "Context 2:\n",
      "I started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.  The dist...\n",
      "\n",
      "Context 3:\n",
      "There weren't any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI....\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from config import RAGConfig\n",
    "\n",
    "# Initialize Bedrock client for retrieval\n",
    "load_dotenv()\n",
    "bedrock_agent = boto3.client('bedrock-agent-runtime', region_name=os.getenv('AWS_BEDROCK_REGION'))\n",
    "\n",
    "def retrieve_context(knowledge_base_id: str, prompt: str):\n",
    "    \"\"\"\n",
    "    Retrieve relevant passages using Bedrock Agent Runtime\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use the same retrieval configuration as in bedrock_rag.py\n",
    "        retrieve_response = bedrock_agent.retrieve(\n",
    "            knowledgeBaseId=knowledge_base_id,\n",
    "            retrievalQuery={\n",
    "                'text': prompt\n",
    "            },\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': RAGConfig.NUMBER_OF_RESULTS\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Extract passages from response\n",
    "        passages = []\n",
    "        for result in retrieve_response.get('retrievalResults', []):\n",
    "            text = result.get('content', {}).get('text', '')\n",
    "            if text:\n",
    "                passages.append(text)\n",
    "                \n",
    "        return passages\n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieval: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Get the input query from first test case\n",
    "input_query = first_case['input']\n",
    "knowledge_base_id = os.getenv('KNOWLEDGE_BASE_ID')\n",
    "\n",
    "# Retrieve context\n",
    "retrieved_contexts = retrieve_context(knowledge_base_id, input_query)\n",
    "\n",
    "print(f\"Input Query: {input_query}\")\n",
    "print(f\"\\nNumber of contexts retrieved: {len(retrieved_contexts)}\")\n",
    "print(\"\\nRetrieved Contexts:\")\n",
    "for i, context in enumerate(retrieved_contexts, 1):\n",
    "    print(f\"\\nContext {i}:\")\n",
    "    print(context[:200] + \"...\" if len(context) > 200 else context)  # Show first 200 chars for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation\n",
    "Generates answer using AWS Bedrock:\n",
    "- Uses retrieved context and input query\n",
    "- Follows RAGConfig.PROMPT_TEMPLATE format\n",
    "- Parameters from ModelConfig (max_gen_len, temperature, top_p)\n",
    "- Handles multiple response formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Enhanced Prompt ===\n",
      "Based on the following context, please answer the question.\n",
      "\n",
      "Context:\n",
      "What these programs really showed was that there's a subset of natural language that's a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.  So I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It's scary to think how little I knew about Lisp hacking when I started writing that book. But there's nothing like writing a book about something to help you learn it. The book, On Lisp, wasn't published till 1993, but I wrote much of it in grad school.  Computer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things.\n",
      "I started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.  The distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn't originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]  McCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.  McCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach.\n",
      "There weren't any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn't happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.  For my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief ‚Äî hard to imagine now, but not unique in 1985 ‚Äî that it was already climbing the lower slopes of intelligence.  I had gotten into a program at Cornell that didn't make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\"\n",
      "\n",
      "Question: What aspects of Lisp contributed to its prominence over PL/I in AI programming?\n",
      "\n",
      "Answer:\n",
      "=====================\n",
      "\n",
      "=== Generated Response ===\n",
      " Lisp's origins as a formal model of computation, its power and elegance, and its ability to be used to program computers, as well as its being regarded as the language of AI, contributed to its prominence over PL/I in AI programming. Additionally, Lisp's ability to expand one's concept of a program and its suitability for reverse-engineering SHRDLU, a program that the author believed was already climbing the lower slopes of intelligence, also contributed to its popularity in AI programming.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from config import ModelConfig, RAGConfig\n",
    "\n",
    "# Initialize Bedrock runtime client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=os.getenv('AWS_BEDROCK_REGION'))\n",
    "\n",
    "def generate_response(model_id: str, context: list, prompt: str):\n",
    "    \"\"\"\n",
    "    Generate response using Bedrock's LLaMA3 model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create enhanced prompt using the same template\n",
    "        context_text = \"\\n\".join(context)\n",
    "        enhanced_prompt = RAGConfig.PROMPT_TEMPLATE.format(\n",
    "            context=context_text, \n",
    "            question=prompt\n",
    "        )\n",
    "        \n",
    "        # Print enhanced prompt for debugging\n",
    "        print(\"\\n=== Enhanced Prompt ===\")\n",
    "        print(enhanced_prompt)\n",
    "        print(\"=====================\")\n",
    "        \n",
    "        # Invoke LLaMA3 model with same configuration\n",
    "        llm_response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "            body=json.dumps({\n",
    "                \"prompt\": enhanced_prompt,\n",
    "                \"max_gen_len\": ModelConfig.MAX_GEN_LEN,\n",
    "                \"temperature\": ModelConfig.TEMPERATURE,\n",
    "                \"top_p\": ModelConfig.TOP_P\n",
    "            })\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(llm_response[\"body\"].read())\n",
    "        \n",
    "        # Handle response formats\n",
    "        if \"generation\" in response_body:\n",
    "            return response_body[\"generation\"]\n",
    "        elif \"outputs\" in response_body and isinstance(response_body[\"outputs\"], list):\n",
    "            return response_body[\"outputs\"][0].get(\"text\", \"No response generated\")\n",
    "        else:\n",
    "            print(f\"\\nDebug - Received response format: {response_body.keys()}\")\n",
    "            return \"Unexpected response format.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in generate_response: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Generate response for first test case\n",
    "model_id = os.getenv('AWS_BEDROCK_MODEL_ID')\n",
    "input_query = first_case['input']\n",
    "\n",
    "response = generate_response(\n",
    "    model_id=model_id,\n",
    "    context=retrieved_contexts,  # From Cell 2\n",
    "    prompt=input_query\n",
    ")\n",
    "\n",
    "print(\"\\n=== Generated Response ===\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Traid\n",
    "\n",
    "The RAG Triad consists of three key metrics:\n",
    "1. Faithfulness ‚Äì Is the answer grounded in the retrieved context?\n",
    "2. Contextual Relevancy ‚Äì Is the retrieved context relevant to the query?\n",
    "3. Answer Relevancy ‚Äì Is the answer relevant to the query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (1/1) [Time Taken: 00:12, 12.37s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 0.875, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The score is 0.88 because while the response provided valuable insights into Lisp's prominence in AI programming, the mention of SHRDLU's intelligence level strayed from directly comparing Lisp to PL/I, causing a slight decrease in relevance., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The score is 1.00 because there are no contradictions present, indicating perfect alignment between the actual output and the information in the retrieval context., error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.55, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The score is 0.55 because while the retrieval context includes some relevant statements like 'The distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself' and 'But its origins as a model of computation gave it a power and elegance that other languages couldn't match', many statements such as 'understanding natural language' and 'wasn't published till 1993' do not pertain to Lisp's prominence over PL/I, affecting the overall relevancy., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What aspects of Lisp contributed to its prominence over PL/I in AI programming?\n",
      "  - actual output:  Lisp's origins as a formal model of computation, its power and elegance, and its ability to be used to program computers, as well as its being regarded as the language of AI, contributed to its prominence over PL/I in AI programming. Additionally, Lisp's ability to expand one's concept of a program and its suitability for reverse-engineering SHRDLU, a program that the author believed was already climbing the lower slopes of intelligence, also contributed to its popularity in AI programming.\n",
      "  - expected output: Lisp's prominence over PL/I in AI programming can be attributed to several key aspects that aligned well with the needs of AI development:\n",
      "\n",
      "1. **Symbolic Computation**: Lisp was uniquely suited for symbolic computation, a cornerstone of AI programming. It allowed for easy manipulation of symbols and lists, which was essential for representing knowledge and reasoning in AI systems.\n",
      "\n",
      "2. **Flexibility & Extensibility**: The language's inherent flexibility allowed programmers to define their own syntax and new language features easily, enabling rapid experimentation and adaptation to complex AI challenges.\n",
      "\n",
      "3. **Dynamic Typing and Garbage Collection**: Lisp's dynamic typing and automatic memory management via garbage collection allowed AI developers to focus more on problem-solving rather than low-level memory management, which was often cumbersome in languages like PL/I.\n",
      "\n",
      "4. **Interactive Development Environment**: Lisp provided an interactive environment that supported quick prototyping and iterative development, which was crucial for exploring and refining AI algorithms.\n",
      "\n",
      "5. **Recursive Functions**: The language's strong support for recursion made it a natural fit for AI applications requiring iterative and recursive problem-solving methods, such as natural language processing and machine learning.\n",
      "\n",
      "These attributes made Lisp a compelling choice for AI developers, leading to its widespread adoption despite the availability of other languages like PL/I.\n",
      "  - context: [' since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief ‚Äî hard to imagine now, but not unique in 1985 ‚Äî that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things. I had plenty of respect for theory ‚Äî indeed, a sneaking suspicion that it was the more admirable of the two halves ‚Äî but building things seemed so much more exciting.\\n\\nThe problem with systems work, though, was that it didn\\'t last. Any program you wrote today, no matter how good, would be obsolete in a couple decades at best. People might mention your software in footnotes, but no one would actually use it. And indeed, it would seem very feeble work. Only people with a sense of the history of the field would even realize that, in its time, it had been good.\\n\\nThere were some surplus Xerox Dandelions floating around the computer lab at one point. Anyone who wanted one to play around with could have one. I was briefly tempted, but they were so slow by present standards; what was the point? No one else wanted one either, so off they went. That was what happened to systems work.\\n\\nI wanted not just to build things, but to build things that would last.\\n\\nIn this dissatisfied state I went in 1988 to visit Rich Draves at CMU, where he was in grad school. One day I went to visit the Carnegie Institute, where I\\'d spent a lot of time as a', '\\n\\nWhat I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines ‚Äî CPU, disk drives, printer, card reader ‚Äî sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\\n\\nThe first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\\n\\nComputers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he\\'d write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\\n\\nThough I liked programming, I didn\\'t plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn\\'t much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\\n\\nI couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp,', \" had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn't, so we decided we'd try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn't be controlled by the founders. So if Sam said yes, we'd let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he'd take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.\\n\\nShe died on January 15, 2014. We knew this was coming, but it was still hard when it did.\\n\\nI kept working on YC till March, to help get that batch of startups through Demo Day, then I checked out pretty completely. (I still talk to alumni and to new startups working on things I'm interested in, but that only takes a few hours a week.)\\n\\nWhat should I do next? Rtm's advice hadn't included anything about that. I wanted to do something completely different, so I decided I'd paint. I wanted to see how good I could get if I really focused on it. So the day after I stopped working on YC, I started painting. I was rusty and it took a while to get back into shape, but it was at least completely engaging. [18]\\n\\nI spent most of the rest of 2014 painting. I'd never been able to work so uninterruptedly before, and I got to be better than I had been. Not good enough, but better. Then in November, right in the middle of a painting, I ran out of steam. Up till that point I'd always been curious to see how the painting I was working on would turn out, but suddenly finishing this one seemed like a chore. So I stopped working on it and cleaned my brushes and haven't painted since. So far anyway.\\n\\nI realize that sounds rather wimpy. But attention is a zero sum game. If you can choose what to work on, and you choose a project that's not the best one (or at least a good one) for you, then it's getting in the way of another project that is. And at 50 there was some opportunity cost to screwing around.\\n\\nI started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.\\n\\nThe distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn't originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]\\n\\nMcCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.\\n\\nMcCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach. That wouldn't have been feasible at the time. McCarthy tested his interpreter by hand-simulating the execution of programs. But it was already getting close to the limit of interpreters you could test that way ‚Äî indeed, there was a bug in it that McCarthy had overlooked. To test a more complicated interpreter, you'd have had to run it, and computers then weren't powerful enough.\\n\\nNow they are, though. Now you could continue using McCarthy's axiomatic approach till you'd defined a complete programming language. And as long as every change you made to McCarthy's Lisp was a discovered\"]\n",
      "  - retrieval context: [\"What these programs really showed was that there's a subset of natural language that's a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.  So I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It's scary to think how little I knew about Lisp hacking when I started writing that book. But there's nothing like writing a book about something to help you learn it. The book, On Lisp, wasn't published till 1993, but I wrote much of it in grad school.  Computer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things.\", \"I started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.  The distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn't originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]  McCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.  McCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach.\", 'There weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.  For my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief ‚Äî hard to imagine now, but not unique in 1985 ‚Äî that it was already climbing the lower slopes of intelligence.  I had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\"']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "Contextual Relevancy: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=False, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.7, success=True, score=0.875, reason=\"The score is 0.88 because while the response provided valuable insights into Lisp's prominence in AI programming, the mention of SHRDLU's intelligence level strayed from directly comparing Lisp to PL/I, causing a slight decrease in relevance.\", strict_mode=False, evaluation_model='gpt-4o-mini', error=None, evaluation_cost=0.000405, verbose_logs='Statements:\\n[\\n    \"Lisp originated as a formal model of computation.\",\\n    \"Lisp is regarded as the language of AI.\",\\n    \"Lisp has power and elegance in programming.\",\\n    \"Lisp is prominent over PL/I in AI programming.\",\\n    \"Lisp can expand one\\'s concept of a program.\",\\n    \"Lisp is suitable for reverse-engineering SHRDLU.\",\\n    \"The author believed SHRDLU was climbing the lower slopes of intelligence.\",\\n    \"Lisp\\'s popularity in AI programming is due to various factors.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The statement about SHRDLU\\'s intelligence level does not directly address Lisp\\'s qualities compared to PL/I.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Faithfulness', threshold=0.7, success=True, score=1.0, reason='The score is 1.00 because there are no contradictions present, indicating perfect alignment between the actual output and the information in the retrieval context.', strict_mode=False, evaluation_model='gpt-4o-mini', error=None, evaluation_cost=0.00069165, verbose_logs='Truths (limit=None):\\n[\\n    \"Lisp was interesting for its own sake and not just for its association with AI.\",\\n    \"The author wrote a book about Lisp hacking titled \\'On Lisp.\\'\",\\n    \"\\'On Lisp\\' wasn\\'t published until 1993.\",\\n    \"The author wrote much of \\'On Lisp\\' during grad school.\",\\n    \"McCarthy\\'s 1960 Lisp did nothing more than interpret Lisp expressions.\",\\n    \"McCarthy invented Lisp as a formal model of computation.\",\\n    \"The first machine language translation of Lisp was done by Steve Russell on the IBM 704.\",\\n    \"Lisp started to be used as a programming language after Russell\\'s translation.\",\\n    \"In the author\\'s undergraduate thesis, they reverse-engineered SHRDLU.\",\\n    \"Lisp was regarded as the language of AI during the author\\'s time at Cornell.\",\\n    \"The author experienced a significant expansion of their concept of a program while learning Lisp.\"\\n] \\n \\nClaims:\\n[\\n    \"Lisp originated as a formal model of computation.\",\\n    \"Lisp is regarded as the language of AI.\",\\n    \"Lisp is powerful and elegant.\",\\n    \"Lisp can be used to program computers.\",\\n    \"Lisp is prominent over PL/I in AI programming.\",\\n    \"Lisp expands one\\'s concept of a program.\",\\n    \"Lisp is suitable for reverse-engineering SHRDLU.\",\\n    \"The author believed SHRDLU was climbing the lower slopes of intelligence.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Contextual Relevancy', threshold=0.7, success=False, score=0.55, reason=\"The score is 0.55 because while the retrieval context includes some relevant statements like 'The distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself' and 'But its origins as a model of computation gave it a power and elegance that other languages couldn't match', many statements such as 'understanding natural language' and 'wasn't published till 1993' do not pertain to Lisp's prominence over PL/I, affecting the overall relevancy.\", strict_mode=False, evaluation_model='gpt-4o-mini', error=None, evaluation_cost=0.0011849999999999999, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Lisp was interesting for its own sake and not just for its association with AI.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"There was an unbridgeable gap between what they could do and actually understanding natural language.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'understanding natural language\\' which does not directly pertain to Lisp\\'s prominence over PL/I in AI programming.\"\\n            },\\n            {\\n                \"statement\": \"I decided to focus on Lisp.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It\\'s scary to think how little I knew about Lisp hacking when I started writing that book.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement \\'how little I knew about Lisp hacking\\' does not provide relevant information regarding Lisp\\'s contributions to its prominence over PL/I.\"\\n            },\\n            {\\n                \"statement\": \"The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement contains \\'wasn\\'t published till 1993,\\' which does not directly address Lisp\\'s prominence over PL/I in AI programming.\"\\n            },\\n            {\\n                \"statement\": \"Computer Science is an uneasy alliance between two halves, theory and systems.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement discussing \\'Computer Science\\' does not relate specifically to Lisp\\'s prominence in AI programming.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It wasn\\'t originally intended as a programming language in the ordinary sense.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It was meant to be a formal model of computation, an alternative to the Turing machine.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"McCarthy didn\\'t realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"from that point Lisp started also to be a programming language in the ordinary sense.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"But its origins as a model of computation gave it a power and elegance that other languages couldn\\'t match.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"McCarthy\\'s 1960 Lisp did nothing more than interpret Lisp expressions.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement mentions \\'interpreting Lisp expressions\\' which does not directly address aspects of Lisp contributing to its prominence over PL/I.\"\\n            },\\n            {\\n                \"statement\": \"It was missing a lot of things you\\'d want in a programming language.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement about it being \\'missing a lot of things you\\'d want in a programming language\\' is not relevant to why Lisp was prominent over PL/I.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Lisp was regarded as the language of AI.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'The commonly used programming languages then were pretty primitive\\' which does not directly relate to the aspects of Lisp\\'s prominence over PL/I in AI programming.\"\\n            },\\n            {\\n                \"statement\": \"The default language at Cornell was a Pascal-like language called PL/I.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'The default language at Cornell was a Pascal-like language called PL/I\\' which does not address the aspects contributing to Lisp\\'s prominence in AI.\"\\n            },\\n            {\\n                \"statement\": \"Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For my undergraduate thesis, I reverse-engineered SHRDLU.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'For my undergraduate thesis, I reverse-engineered SHRDLU\\' which is not directly related to how Lisp contributed to its prominence over PL/I.\"\\n            }\\n        ]\\n    }\\n]')], conversational=False, multimodal=False, input='What aspects of Lisp contributed to its prominence over PL/I in AI programming?', actual_output=\" Lisp's origins as a formal model of computation, its power and elegance, and its ability to be used to program computers, as well as its being regarded as the language of AI, contributed to its prominence over PL/I in AI programming. Additionally, Lisp's ability to expand one's concept of a program and its suitability for reverse-engineering SHRDLU, a program that the author believed was already climbing the lower slopes of intelligence, also contributed to its popularity in AI programming.\", expected_output=\"Lisp's prominence over PL/I in AI programming can be attributed to several key aspects that aligned well with the needs of AI development:\\n\\n1. **Symbolic Computation**: Lisp was uniquely suited for symbolic computation, a cornerstone of AI programming. It allowed for easy manipulation of symbols and lists, which was essential for representing knowledge and reasoning in AI systems.\\n\\n2. **Flexibility & Extensibility**: The language's inherent flexibility allowed programmers to define their own syntax and new language features easily, enabling rapid experimentation and adaptation to complex AI challenges.\\n\\n3. **Dynamic Typing and Garbage Collection**: Lisp's dynamic typing and automatic memory management via garbage collection allowed AI developers to focus more on problem-solving rather than low-level memory management, which was often cumbersome in languages like PL/I.\\n\\n4. **Interactive Development Environment**: Lisp provided an interactive environment that supported quick prototyping and iterative development, which was crucial for exploring and refining AI algorithms.\\n\\n5. **Recursive Functions**: The language's strong support for recursion made it a natural fit for AI applications requiring iterative and recursive problem-solving methods, such as natural language processing and machine learning.\\n\\nThese attributes made Lisp a compelling choice for AI developers, leading to its widespread adoption despite the availability of other languages like PL/I.\", context=[' since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief ‚Äî hard to imagine now, but not unique in 1985 ‚Äî that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things. I had plenty of respect for theory ‚Äî indeed, a sneaking suspicion that it was the more admirable of the two halves ‚Äî but building things seemed so much more exciting.\\n\\nThe problem with systems work, though, was that it didn\\'t last. Any program you wrote today, no matter how good, would be obsolete in a couple decades at best. People might mention your software in footnotes, but no one would actually use it. And indeed, it would seem very feeble work. Only people with a sense of the history of the field would even realize that, in its time, it had been good.\\n\\nThere were some surplus Xerox Dandelions floating around the computer lab at one point. Anyone who wanted one to play around with could have one. I was briefly tempted, but they were so slow by present standards; what was the point? No one else wanted one either, so off they went. That was what happened to systems work.\\n\\nI wanted not just to build things, but to build things that would last.\\n\\nIn this dissatisfied state I went in 1988 to visit Rich Draves at CMU, where he was in grad school. One day I went to visit the Carnegie Institute, where I\\'d spent a lot of time as a', '\\n\\nWhat I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines ‚Äî CPU, disk drives, printer, card reader ‚Äî sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\\n\\nThe first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\\n\\nComputers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he\\'d write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\\n\\nThough I liked programming, I didn\\'t plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn\\'t much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\\n\\nI couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp,', \" had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn't, so we decided we'd try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn't be controlled by the founders. So if Sam said yes, we'd let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he'd take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.\\n\\nShe died on January 15, 2014. We knew this was coming, but it was still hard when it did.\\n\\nI kept working on YC till March, to help get that batch of startups through Demo Day, then I checked out pretty completely. (I still talk to alumni and to new startups working on things I'm interested in, but that only takes a few hours a week.)\\n\\nWhat should I do next? Rtm's advice hadn't included anything about that. I wanted to do something completely different, so I decided I'd paint. I wanted to see how good I could get if I really focused on it. So the day after I stopped working on YC, I started painting. I was rusty and it took a while to get back into shape, but it was at least completely engaging. [18]\\n\\nI spent most of the rest of 2014 painting. I'd never been able to work so uninterruptedly before, and I got to be better than I had been. Not good enough, but better. Then in November, right in the middle of a painting, I ran out of steam. Up till that point I'd always been curious to see how the painting I was working on would turn out, but suddenly finishing this one seemed like a chore. So I stopped working on it and cleaned my brushes and haven't painted since. So far anyway.\\n\\nI realize that sounds rather wimpy. But attention is a zero sum game. If you can choose what to work on, and you choose a project that's not the best one (or at least a good one) for you, then it's getting in the way of another project that is. And at 50 there was some opportunity cost to screwing around.\\n\\nI started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.\\n\\nThe distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn't originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]\\n\\nMcCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.\\n\\nMcCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach. That wouldn't have been feasible at the time. McCarthy tested his interpreter by hand-simulating the execution of programs. But it was already getting close to the limit of interpreters you could test that way ‚Äî indeed, there was a bug in it that McCarthy had overlooked. To test a more complicated interpreter, you'd have had to run it, and computers then weren't powerful enough.\\n\\nNow they are, though. Now you could continue using McCarthy's axiomatic approach till you'd defined a complete programming language. And as long as every change you made to McCarthy's Lisp was a discovered\"], retrieval_context=[\"What these programs really showed was that there's a subset of natural language that's a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.  So I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It's scary to think how little I knew about Lisp hacking when I started writing that book. But there's nothing like writing a book about something to help you learn it. The book, On Lisp, wasn't published till 1993, but I wrote much of it in grad school.  Computer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things.\", \"I started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.  The distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn't originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]  McCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.  McCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach.\", 'There weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.  For my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief ‚Äî hard to imagine now, but not unique in 1985 ‚Äî that it was already climbing the lower slopes of intelligence.  I had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\"'])], confident_link=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric, ContextualRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "answer_relevancy_metric = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "faithfulness_metric = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "contextual_relevancy_metric = ContextualRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=first_case['input'],\n",
    "    actual_output=response,\n",
    "    expected_output=first_case['expected_output'],\n",
    "    context=first_case['context'],\n",
    "    retrieval_context=retrieved_contexts\n",
    ")\n",
    "\n",
    "evaluate(test_cases=[test_case], metrics=[answer_relevancy_metric, faithfulness_metric, contextual_relevancy_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Setup\n",
    "Import required packages for custom evaluator:\n",
    "- LangChain AWS integration\n",
    "- DeepEval base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "# from langchain_community.chat_models import BedrockChat\n",
    "from langchain_aws import ChatBedrock\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Evaluator\n",
    "DeepEval compatible AWS Bedrock wrapper:\n",
    "- Implements required LLM interface\n",
    "- Supports sync/async generation\n",
    "- Uses configured model name from env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWSBedrock(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return os.getenv('AWS_EVALUATOR_MODEL_NAME', \"Custom Azure OpenAI Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Evaluator\n",
    "Sets up AWS Bedrock for evaluation:\n",
    "- Creates ChatBedrock instance with env config\n",
    "- Wraps model in DeepEval-compatible interface\n",
    "- Configures generation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "\n",
    "# Initialize the custom model\n",
    "custom_model = ChatBedrock(\n",
    "    region_name=os.getenv('AWS_EVALUATOR_REGION'),\n",
    "    model_id=os.getenv('AWS_EVALUATOR_MODEL_ID'),\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.8,\n",
    "        \"max_gen_len\": 2048\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create our custom LLM class instance\n",
    "aws_bedrock = AWSBedrock(model=custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEval Configuration\n",
    "Sets up evaluation metric:\n",
    "- Assesses: accuracy, completeness, clarity\n",
    "- Uses: input, output, expected, context\n",
    "- Evaluates via custom AWS Bedrock model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEval metric configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Import GEval components\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "\n",
    "# Define accuracy metric\n",
    "accuracy_metric = GEval(\n",
    "    name=\"response_accuracy_metric\",\n",
    "    criteria=\"\"\"Evaluate the response for:\n",
    "1. Factual Accuracy: Information provided matches the source material\n",
    "2. Completeness: All key points from the question are addressed\n",
    "3. Clarity: Response is well-structured and easy to understand\"\"\",\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.EXPECTED_OUTPUT,\n",
    "        LLMTestCaseParams.CONTEXT\n",
    "    ],\n",
    "    model=aws_bedrock  # Using our custom AWS Bedrock model\n",
    ")\n",
    "\n",
    "print(\"GEval metric configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case Creation\n",
    "Prepares evaluation data:\n",
    "- Input: from golden\n",
    "- Actual: RAG generated response\n",
    "- Expected: golden's ground truth\n",
    "- Context: golden's context passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Case Created ===\n",
      "Input Query: What aspects of Lisp contributed to its prominence over PL/I in AI programming?...\n",
      "\n",
      "Actual Output Length: 496 chars\n",
      "Expected Output Length: 1475 chars\n",
      "Context Passages: 3\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "\n",
    "# Get first test case from goldens.json\n",
    "first_case = test_cases[0]\n",
    "\n",
    "# Create LLMTestCase:\n",
    "# - input from JSON\n",
    "# - actual_output from RAG response only\n",
    "# - expected_output from JSON\n",
    "# - context from JSON only\n",
    "test_case = LLMTestCase(\n",
    "    input=first_case['input'],\n",
    "    actual_output=response,  # From RAG's response\n",
    "    expected_output=first_case['expected_output'],\n",
    "    context=first_case['context']  \n",
    ")\n",
    "\n",
    "print(\"=== Test Case Created ===\")\n",
    "print(f\"Input Query: {test_case.input[:100]}...\")\n",
    "print(f\"\\nActual Output Length: {len(test_case.actual_output) if test_case.actual_output else 0} chars\")\n",
    "print(f\"Expected Output Length: {len(test_case.expected_output)} chars\")\n",
    "print(f\"Context Passages: {len(test_case.context)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "Executes GEval assessment:\n",
    "- Evaluates test case against metric\n",
    "- Shows score, threshold, success/fail\n",
    "- Provides detailed analysis rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">response_accuracy_metric </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using </span><span style=\"color: #374151; text-decoration-color: #374151\">\"LLaMA3-70B Evaluator\"</span><span style=\"color: #374151; text-decoration-color: #374151\">  # </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">Custom display name, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mresponse_accuracy_metric \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing \u001b[0m\u001b[38;2;55;65;81m\"LLaMA3-70B Evaluator\"\u001b[0m\u001b[38;2;55;65;81m  # \u001b[0m\n",
       "\u001b[38;2;55;65;81mCustom display name, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (1/1) [Time Taken: 00:03,  3.67s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ response_accuracy_metric (GEval) (score: 0.8, threshold: 0.5, strict: False, evaluation model: \"LLaMA3-70B Evaluator\"  # Custom display name, reason: The Actual Output partially matches the Expected Output, covering some key points such as Lisp's symbolic computation and flexibility, but lacks clarity and completeness, failing to address all aspects contributing to Lisp's prominence over PL/I in AI programming., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What aspects of Lisp contributed to its prominence over PL/I in AI programming?\n",
      "  - actual output:  Lisp's origins as a formal model of computation, its power and elegance, and its ability to be used to program computers, as well as its being regarded as the language of AI, contributed to its prominence over PL/I in AI programming. Additionally, Lisp's ability to expand one's concept of a program and its suitability for reverse-engineering SHRDLU, a program that the author believed was already climbing the lower slopes of intelligence, also contributed to its popularity in AI programming.\n",
      "  - expected output: Lisp's prominence over PL/I in AI programming can be attributed to several key aspects that aligned well with the needs of AI development:\n",
      "\n",
      "1. **Symbolic Computation**: Lisp was uniquely suited for symbolic computation, a cornerstone of AI programming. It allowed for easy manipulation of symbols and lists, which was essential for representing knowledge and reasoning in AI systems.\n",
      "\n",
      "2. **Flexibility & Extensibility**: The language's inherent flexibility allowed programmers to define their own syntax and new language features easily, enabling rapid experimentation and adaptation to complex AI challenges.\n",
      "\n",
      "3. **Dynamic Typing and Garbage Collection**: Lisp's dynamic typing and automatic memory management via garbage collection allowed AI developers to focus more on problem-solving rather than low-level memory management, which was often cumbersome in languages like PL/I.\n",
      "\n",
      "4. **Interactive Development Environment**: Lisp provided an interactive environment that supported quick prototyping and iterative development, which was crucial for exploring and refining AI algorithms.\n",
      "\n",
      "5. **Recursive Functions**: The language's strong support for recursion made it a natural fit for AI applications requiring iterative and recursive problem-solving methods, such as natural language processing and machine learning.\n",
      "\n",
      "These attributes made Lisp a compelling choice for AI developers, leading to its widespread adoption despite the availability of other languages like PL/I.\n",
      "  - context: [' since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief ‚Äî hard to imagine now, but not unique in 1985 ‚Äî that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things. I had plenty of respect for theory ‚Äî indeed, a sneaking suspicion that it was the more admirable of the two halves ‚Äî but building things seemed so much more exciting.\\n\\nThe problem with systems work, though, was that it didn\\'t last. Any program you wrote today, no matter how good, would be obsolete in a couple decades at best. People might mention your software in footnotes, but no one would actually use it. And indeed, it would seem very feeble work. Only people with a sense of the history of the field would even realize that, in its time, it had been good.\\n\\nThere were some surplus Xerox Dandelions floating around the computer lab at one point. Anyone who wanted one to play around with could have one. I was briefly tempted, but they were so slow by present standards; what was the point? No one else wanted one either, so off they went. That was what happened to systems work.\\n\\nI wanted not just to build things, but to build things that would last.\\n\\nIn this dissatisfied state I went in 1988 to visit Rich Draves at CMU, where he was in grad school. One day I went to visit the Carnegie Institute, where I\\'d spent a lot of time as a', '\\n\\nWhat I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines ‚Äî CPU, disk drives, printer, card reader ‚Äî sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\\n\\nThe first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\\n\\nComputers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he\\'d write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\\n\\nThough I liked programming, I didn\\'t plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn\\'t much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\\n\\nI couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp,', \" had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn't, so we decided we'd try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn't be controlled by the founders. So if Sam said yes, we'd let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he'd take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.\\n\\nShe died on January 15, 2014. We knew this was coming, but it was still hard when it did.\\n\\nI kept working on YC till March, to help get that batch of startups through Demo Day, then I checked out pretty completely. (I still talk to alumni and to new startups working on things I'm interested in, but that only takes a few hours a week.)\\n\\nWhat should I do next? Rtm's advice hadn't included anything about that. I wanted to do something completely different, so I decided I'd paint. I wanted to see how good I could get if I really focused on it. So the day after I stopped working on YC, I started painting. I was rusty and it took a while to get back into shape, but it was at least completely engaging. [18]\\n\\nI spent most of the rest of 2014 painting. I'd never been able to work so uninterruptedly before, and I got to be better than I had been. Not good enough, but better. Then in November, right in the middle of a painting, I ran out of steam. Up till that point I'd always been curious to see how the painting I was working on would turn out, but suddenly finishing this one seemed like a chore. So I stopped working on it and cleaned my brushes and haven't painted since. So far anyway.\\n\\nI realize that sounds rather wimpy. But attention is a zero sum game. If you can choose what to work on, and you choose a project that's not the best one (or at least a good one) for you, then it's getting in the way of another project that is. And at 50 there was some opportunity cost to screwing around.\\n\\nI started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.\\n\\nThe distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn't originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]\\n\\nMcCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.\\n\\nMcCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach. That wouldn't have been feasible at the time. McCarthy tested his interpreter by hand-simulating the execution of programs. But it was already getting close to the limit of interpreters you could test that way ‚Äî indeed, there was a bug in it that McCarthy had overlooked. To test a more complicated interpreter, you'd have had to run it, and computers then weren't powerful enough.\\n\\nNow they are, though. Now you could continue using McCarthy's axiomatic approach till you'd defined a complete programming language. And as long as every change you made to McCarthy's Lisp was a discovered\"]\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "response_accuracy_metric (GEval): 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Results ===\n",
      "Metric: response_accuracy_metric (GEval)\n",
      "Score: 0.8000\n",
      "Threshold: 0.5\n",
      "Success: True\n",
      "Model Used: \"LLaMA3-70B Evaluator\"  # Custom display name\n",
      "\n",
      "Detailed Analysis:\n",
      "The Actual Output partially matches the Expected Output, covering some key points such as Lisp's symbolic computation and flexibility, but lacks clarity and completeness, failing to address all aspects contributing to Lisp's prominence over PL/I in AI programming.\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "\n",
    "result = evaluate(\n",
    "    test_cases=[test_case],\n",
    "    metrics=[accuracy_metric]  # Using the custom defined 'accuracy_metric'\n",
    ")\n",
    "\n",
    "# Extract and print the detailed results\n",
    "metric_result = result.test_results[0].metrics_data[0]  # Get first test case's metric\n",
    "\n",
    "print(\"=== Evaluation Results ===\")\n",
    "print(f\"Metric: {metric_result.name}\")\n",
    "print(f\"Score: {metric_result.score:.4f}\")\n",
    "print(f\"Threshold: {metric_result.threshold}\")\n",
    "print(f\"Success: {metric_result.success}\")\n",
    "print(f\"Model Used: {metric_result.evaluation_model}\")\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "print(metric_result.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Generation\n",
    "Creates Excel report with two sheets:\n",
    "- Summary: timestamp, score, pass/fail\n",
    "- Details: full test case results\n",
    "- Auto-formatted for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel report generated successfully: reports\\rag_evaluation_report_20250530_152953.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def generate_excel_reports(test_case, metric_result, report_dir='reports'):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    excel_file = os.path.join(report_dir, f'rag_evaluation_report_{timestamp}.xlsx')\n",
    "    \n",
    "    # Create Summary DataFrame\n",
    "    summary_data = {\n",
    "        'Metric': ['Timestamp', 'Total Test Cases', 'Overall Score', 'Pass/Fail', 'Model Used'],\n",
    "        'Value': [\n",
    "            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            1,  # Will be modified for production\n",
    "            f\"{metric_result.score:.4f}\",\n",
    "            'PASS' if metric_result.success else 'FAIL',\n",
    "            metric_result.evaluation_model\n",
    "        ]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Create Detailed Results DataFrame - Now with each test case as a row\n",
    "    detailed_data = {\n",
    "        'Test ID': [1],  # Will increment for multiple test cases\n",
    "        'Input Query': [test_case.input],\n",
    "        'Expected Output': [test_case.expected_output],\n",
    "        'Actual Output': [test_case.actual_output],\n",
    "        'Score': [f\"{metric_result.score:.4f}\"],\n",
    "        'Threshold': [metric_result.threshold],\n",
    "        'Success': [metric_result.success],\n",
    "        'Analysis': [metric_result.reason]\n",
    "    }\n",
    "    detailed_df = pd.DataFrame(detailed_data)\n",
    "    \n",
    "    # Create Excel writer object\n",
    "    with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "        # Write each dataframe to a different worksheet\n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "        detailed_df.to_excel(writer, sheet_name='Detailed Results', index=False)\n",
    "        \n",
    "        # Auto-adjust columns' width\n",
    "        for sheet_name in writer.sheets:\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            for idx, col in enumerate(worksheet.columns, 1):\n",
    "                max_length = 0\n",
    "                column = worksheet.column_dimensions[chr(64 + idx)]\n",
    "                for cell in col:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = min(max_length + 2, 100)  # Cap width at 100\n",
    "                column.width = adjusted_width\n",
    "\n",
    "    print(f\"Excel report generated successfully: {excel_file}\")\n",
    "\n",
    "# Generate the Excel report\n",
    "generate_excel_reports(test_case, metric_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
